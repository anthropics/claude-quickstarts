<project_specification>
  <project_name>Legal Argument Workbench - Autonomous Coding Prototype</project_name>

  <overview>
    Build a small but realistic prototype of a “Legal Argument Workbench” to evaluate whether the
    autonomous-coding workflow (initializer agent + iterative coding agents + feature_list.json + git)
    can replace much of a developer team for an early product slice.

    This is NOT the full Theia-based workstation. This prototype must deliver a stable backend contract
    and a minimal web UI that exercises it end-to-end, with strict provenance: no extracted claim or evidence
    is allowed without citations that point back to exact source text spans.
  </overview>

  <technology_stack>
    <constraints>
      - Environment is the autonomous-coding sandbox allowlist: only these shell commands are available:
        ls, cat, head, tail, wc, grep, cp, mkdir, chmod, pwd, npm, node, git, ps, lsof, sleep, pkill, init.sh
      - Do NOT rely on npx, curl, python, pip, wget, apt, docker, or other non-allowlisted commands.
      - App MUST listen on 0.0.0.0 and use process.env.PORT when set, else 3000.
    </constraints>

    <backend>
      <runtime>Node.js</runtime>
      <framework>Express</framework>
      <database>SQLite (better-sqlite3)</database>
      <search>SQLite FTS5 (full-text search) OR deterministic TF-IDF implemented in Node</search>
      <jobs>In-process async job runner (queue + worker loop)</jobs>
      <streaming>SSE for job progress updates (EventSource in browser)</streaming>
    </backend>

    <frontend>
      <approach>Minimal static web UI served by Express</approach>
      <libraries>
        - Vanilla HTML/CSS/JS (no build step)
        - Optional: marked.js via CDN for Markdown rendering (or render in &lt;pre&gt;)</libraries>
    </frontend>

    <optional_llm_mode>
      - Provide a pluggable “analysis engine” interface with two implementations:
        1) deterministic (default; used in tests; no network calls)
        2) llm (optional; can call Anthropic if ANTHROPIC_API_KEY is provided)
      - Tests MUST use deterministic mode so results are stable and offline.
    </optional_llm_mode>
  </technology_stack>

  <prerequisites>
    <environment_setup>
      - Must run in GitHub Codespaces.
      - Provide init.sh that installs dependencies, runs tests, and starts the server.
      - Provide sample data (a tiny built-in dataset) for demo.
    </environment_setup>
  </prerequisites>

  <core_features>

    <workspaces_and_documents>
      - Create, list, and view workspaces (case/matter containers).
      - Upload documents as plain text (title + text).
      - Store documents in SQLite.
      - Document detail view shows the full text (for verification) and basic metadata.
    </workspaces_and_documents>

    <retrieval_with_citations>
      - Search within a workspace using POST /api/workspaces/:id/search.
      - Return topK passages with scores.
      - Every search result MUST include a citation object with:
        documentId, documentTitle, startOffset, endOffset, excerpt.
      - Offsets MUST match the excerpt exactly (server must validate).
      - UI displays results with excerpt and a “jump to source” view showing the excerpt in context.
    </retrieval_with_citations>

    <async_jobs_and_artifacts>
      - Start a job with POST /api/workspaces/:id/jobs.
      - Support job types:
        1) argument_outline  (claims + evidence + memo)
        2) argument_map      (graph of supports/attacks + citations)
      - Jobs run asynchronously and expose:
        GET /api/jobs/:jobId (status/progress)
        GET /api/jobs/:jobId/events (SSE progress stream)
      - When done, jobs produce artifacts retrievable via:
        GET /api/jobs/:jobId/artifacts
        GET /api/artifacts/:artifactId
    </async_jobs_and_artifacts>

    <artifacts_formats>
      <claims_artifact>
        - List of claims. Each claim includes stance (pro/con/neutral), confidence, and at least 1 citation.
      </claims_artifact>
      <evidence_artifact>
        - Evidence items linked to claimId. Each evidence has confidence and at least 1 citation.
      </evidence_artifact>
      <memo_artifact>
        - Markdown memo that groups claims by stance and embeds inline citation markers like [CIT:xxxx].
      </memo_artifact>
      <argument_map_artifact>
        - JSON graph with nodes (claims) and edges (supports/attacks).
        - Every edge MUST include at least 1 citation (source excerpt supporting that relation).
      </argument_map_artifact>

      <strict_provenance_rule>
        - Hard rule: no claim/evidence/edge is allowed without citations.length &gt;= 1.
        - If the engine cannot produce a citation for an item, it must omit the item.
      </strict_provenance_rule>
    </artifacts_formats>

    <minimal_web_ui>
      - Single-page UI served from /.
      - Left column: Workspace selector + document upload + document list.
      - Middle column: Search box + search results (with citation display and “open source”).
      - Right column: Job runner + status + artifacts tabs:
        Claims | Evidence | Argument Map | Memo
      - Argument Map can be rendered as a simple SVG graph (no heavy libs required).
      - Use readable styling and responsive layout (works on narrow screens).
    </minimal_web_ui>

    <operability>
      - init.sh must:
        1) npm install
        2) npm test
        3) start server
        4) print the URL and key endpoints
      - npm test must run via node --test (no jest).
      - Provide README.md with Codespaces instructions and demo steps.
    </operability>

  </core_features>

  <api_contract>

    <health>
      GET /api/health -> 200 { "status": "ok" }
    </health>

    <workspaces>
      POST /api/workspaces
        Body: { "name": string }
        -> 201 Workspace
      GET /api/workspaces -> 200 Workspace[]
      GET /api/workspaces/:workspaceId -> 200 Workspace or 404
    </workspaces>

    <documents>
      POST /api/workspaces/:workspaceId/documents
        Body: { "title": string, "text": string }
        -> 201 DocumentSummary
      GET /api/workspaces/:workspaceId/documents
        -> 200 DocumentSummary[]
      GET /api/workspaces/:workspaceId/documents/:documentId
        -> 200 DocumentDetail or 404
    </documents>

    <search>
      POST /api/workspaces/:workspaceId/search
        Body: { "query": string, "topK": number }
        -> 200 { "query": string, "results": Passage[] }
    </search>

    <jobs>
      POST /api/workspaces/:workspaceId/jobs
        Body: { "type": "argument_outline"|"argument_map", "input": { "question": string } }
        -> 202 Job
      GET /api/jobs/:jobId -> 200 Job or 404
      GET /api/jobs/:jobId/artifacts -> 200 { "jobId": string, "artifacts": ArtifactIndex[] }
      GET /api/jobs/:jobId/events -> SSE stream with progress updates
    </jobs>

    <artifacts>
      GET /api/artifacts/:artifactId -> 200 Artifact
    </artifacts>

  </api_contract>

  <database_schema>
    <tables>
      <workspaces>
        - id TEXT PRIMARY KEY
        - name TEXT NOT NULL
        - created_at TEXT NOT NULL
      </workspaces>

      <documents>
        - id TEXT PRIMARY KEY
        - workspace_id TEXT NOT NULL
        - title TEXT NOT NULL
        - text TEXT NOT NULL
        - created_at TEXT NOT NULL
        - FOREIGN KEY(workspace_id) REFERENCES workspaces(id)
      </documents>

      <jobs>
        - id TEXT PRIMARY KEY
        - workspace_id TEXT NOT NULL
        - type TEXT NOT NULL
        - status TEXT NOT NULL
        - progress INTEGER NOT NULL DEFAULT 0
        - input_json TEXT NOT NULL
        - error_json TEXT NULL
        - created_at TEXT NOT NULL
        - started_at TEXT NULL
        - finished_at TEXT NULL
      </jobs>

      <artifacts>
        - id TEXT PRIMARY KEY
        - job_id TEXT NOT NULL
        - type TEXT NOT NULL
        - payload_json TEXT NOT NULL  (memo can be stored as { markdown: "..." })
        - created_at TEXT NOT NULL
        - FOREIGN KEY(job_id) REFERENCES jobs(id)
      </artifacts>
    </tables>
  </database_schema>

  <acceptance_testing>
    - The initializer agent MUST create feature_list.json with exactly 80 tests.
    - Tests must cover: API contract, citation correctness, job lifecycle, SSE updates, artifacts schemas,
      UI flows, init.sh operability.
    - At least 15 tests must have 10+ steps (full end-to-end flows).
  </acceptance_testing>

</project_specification>
